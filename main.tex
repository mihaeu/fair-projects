\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}

\date{}

\begin{document}

\section{Fair Projects - Analyse eines MEAN
Stacks}\label{fair-projects---analyse-eines-mean-stacks}

\subsection{Begriffsdefinitionen (für
uns)}\label{begriffsdefinitionen-fuxfcr-uns}

Damit es einheitlich bleibt (offen für Diskussion):

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \emph{Anwendung}: Applikation, Application, App
\item
  \emph{Benutzer}: User, Anwender
\item
  \emph{3rd-Party}: ???
\item
  \emph{veraltet}: deprecated?
\item
  \emph{Javascript}: JavaScript, JS?
\item
  \emph{Erweiterungen}: Plugins, Add-Ons, Extensions
\item
  \emph{Open-Source}: opensource, open source
\item
  \emph{Repository}: repo
\item
  \emph{Website}: Webseite, Homepage, ???
\item
  \emph{Callbacks}: anonyme Funktionen, Closures (nicht das gleiche,
  weiss ich, aber gibt es in JS eh nicht), ???
\item
  \emph{Entwicklungsumgebung}: IDE, Webstorm, Netbeans, \ldots{}
\end{itemize}

\begin{quote}
Bitte einheitliche Begriffe verwenden und am besten immer die offizielle
Schreibweise verwenden (z.B. MEAN.IO). Auch Wörter wie App, Applikation,
Application oder Anwendung sollten nicht gleichzeitig verwendet werden.
\end{quote}

\begin{quote}
Wir schreiben keine extrem wissenschaftliche Arbeit, aber trotzdem
sollten Aussagen belegt werden. Installation von Meteor ist z.B. nur
einfach, wenn man es selbst in ein paar Minuten hinbekommen hat.
Aussagen von den Herstellern über eigene Features sind keine ordentliche
Quelle.
\end{quote}

Software Architektur - Wintersemester 2015/16

\subsection{Einführung (Michi)}\label{einfuxfchrung-michi}

\emph{Diesen Teil werde ich ganz am Schluss nochmal neu schreiben,
deswegen soweit erstmal ignorieren.}

Im Bereich der Webentwicklung wurde zur Entwicklung der Backends in den
letzten zehn Jahren u.a. die Programmiersprachen Java, C, PHP, Ruby und
Python verwendet. Auf Grund der Unterstützung der meisten Browser war
(von Applets und anderen für bestimmte Browser entwickelte Technologien)
JavaScript nur im Frontend im Einsatz. 2009 wurde eine JavaScript
Runtime (NodeJS) veröffentlicht. Diese ermöglicht die Ausführung von
JavaScript Code außerhalb des Browsers. Seitdem kann JavaScript sowohl
im Front- als auch im Backend verwendet werden.

Ziel dieser Arbeit ist es anhand einer Fallstudie die Vor- und Nachteile
einer ausschließlich in JavaScript entwickelten Anwendung zu zeigen. Die
Fallstudie verwendet dabei den sog. MEAN Stack (\textbf{M}ongoDB,
\textbf{E}xpress, \textbf{A}ngular, \textbf{N}odeJS), bei dem sämtliche
Technologien mit JavaScript verbunden sind.

\subsubsection{Definition (Fabi)}\label{definition-fabi}

\emph{was ist MEAN}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  ganz grobe Definition
\item
  Technologien im Detail spaeter
\item
  wer hat es gepraegt?
\item
  wer verwendet es? (das evtl. unter \hyperref[motivation]{Motivation})
\end{itemize}

\subsubsection{Motivation (Markus)}\label{motivation-markus}

Ein Großteil aller Webanwendungen ist in der Skriptsprache PHP
geschrieben. So werden über 80\% aller Anwendungen damit geschrieben und
ein verschwindend geringer Anteil von nur 0,1\% in JavaScript. Dennoch
stellt ein Grund sich näher mit dem MEAN Stack zu befassen die Tatsache
dar, dass ein klarer Trend zu JavaScript erkennbar ist. So ist das
Interesse in den letzten Jahren enorm gestiegen wie auch auf TODO
erkennbar ist. Dort ist die Steigerung an Suchanfragen zu dem Thema
NodeJS angegeben. Im Vergleich dazu ist das Interesse an beispielsweise
PHP entsprechend gesunken. Auch ist der Bekanntheitsgrad von den anderen
Komponenten wie MongoDB oder AngularJS stark gestiegen. Selbst große
Firmen wie RedBull oder Netflix setzen Teile davon ein. Oftmals wird das
durch die verkürzte Entwicklungszeit zur Erstellung von Webanwendungen
und durch die gesteigerte Performanz begründet. Zudem hat es gewisse
Vorteile für Unternehmen, dass es leichter fällt agile Methoden
einzuführen. Meist werden Aufgaben in die Teile Frontend und Backend
aufgeteilt und von unterschiedlichen Personen erarbeitet.
Frontendentwicklern, die sich mit den Technologien HTML, CSS und
JavaScript auskennen und Backendentwicklern, die nur die serverseitigen
Komponenten mit beispielsweise PHP und MySQL bearbeiten. Da im MEAN
Stack, NodeJS, Express und AngularJS auf JavaScript basieren und sogar
MongoDB JavaScript ausführen kann, können nun die Aufgaben anderes
aufgeteilt werden. So ist es nicht mehr nötig nach Frondend und Backend
zu trennen sondern die Aufgaben vertikal zu schneiden, wodurch jeder
Entwickler alle Bereiche eines Features bearbeiten kann. Vgl.
Elephant-Carpaccio von Alistair Cockburn. Grund genug sich näher mit den
einzelnen Komponenten zu beschäftigen.

\subsection{Fallstudie: Fair Projects}\label{fallstudie-fair-projects}

\subsubsection{Einleitung, Idee, Motivation, bla
(Markus)}\label{einleitung-idee-motivation-bla-markus}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Mockups
\item
  Architektur
\item
  REST API (bitte kurz definieren, damit ich mich darauf beziehen kann)
\item
  Erklärung der Funktionen
\item
  etc.
\end{itemize}

\subsubsection{MongoDB (Fabian)}\label{mongodb-fabian}

\paragraph{Einleitung}\label{einleitung}

Die Entwicklung von MongoDB wurde im Jahr 2007 von dem Unternehmen 10gen
ins Leben gerufen. Hierfür wurde die Programmiersprache C++ verwendet.
Da die Datenmengen durch BigData heutzutage rasant steigen
(https://www.fraunhofer.de/content/dam/zv/de/forschungsthemen/kommunikation/bigdata/Innovationspotenzialanalyse\_Big-Data\_Fraunhofer-IAIS.pdf)
werden die Skalierbarkeit und die Performanz bei großen Datenmengen zu
immer wichtigeren Themen. MongoDB wirbt mit agility, scalability und
performance. Dies soll durch denn Einsatz von verteilten Systemen
ermöglicht werden. Der Name mongo leitet sich aus dem Wort humongous ab,
welches gigantisch bedeutet. Hierdurch wird auf die Idee eine Datenbank
für große Datenmengen zu entwickeln angespielt. Laut einem Ranking
(https://db-engines.com/de/ranking) von 2016 steht MongoDB auf dem
vierten Platz der populärsten Datenbanken. Damit ist sie hinter drei
klassischen Relational Database Management System (RDBMS) die populärste
NoSQL-Datenbank.

\paragraph{Konzepte}\label{konzepte}

Eine herkömmliche RDBMS besteht aus Datenbanktabellen, die einem festen
Schema unterliegen. Bei MongoDB dagegen handelt es sich um eine
Schema-freie, dokumentenbasierte Open-Source-Datenbank. Diese beinhaltet
Sammlungen, die jeweils aus mehreren Dokumente ohne ein festes Schema
bestehen. Jedes Dokument darin kann sich von den Feldern und Strukturen
von den anderen unterscheiden. Dokumente bestehen aus mehreren
Schlüsselwert-Paaren und stellen die Basiseinheit für Daten dar. Die
hierbei verwendbaren Datentypen sind die bekannten Standard-Datentypen
(Integer, Float, Boolean, String, Array), Date, Embedded-Doc, DBRef und
ObjectID. Es gibt unterschiedliche Wege in der Datenbank zu
referenzieren. Dies kann durch Verschachtelung der Dokumente geschehen.
Allerdings führt dies zu einer hohen Komplexität, wenn ein update auf
eine verschachtelte Information durchgeführt werden soll. Bei der
ObjectID handelt es sich um die Standard ID, die jedes Dokument
aufweist. Diese wird bei der Erzeugung eines jeden Dokuments generiert
und ist durch ihren komplexen Aufbau eindeutig. Durch Verwendung der
ObjectID können auch Referenzen hergestellt werden. Bei Verwendung von
ObjectID handelt es sich im Gegensatz zu verschachtelten Dokumenten um
einen ``echten'' Join. Der DBRef entspricht dem Fremdschlüssel aus dem
RDBMS. Also dient er als Identifier für Dokument / Collection /
Datenbank. MongoDB verwendet eine integrierte Query Language. Durch
diese können die Create, Read, Update, Delete (CRUD) Operationen
realisiert werden.

Die Replikationen spielen bei NoSQL-Datenbanken eine zentrale Rolle. Die
Replikationen bestimmen über die Synchronisierung von Daten über mehrere
Server. Bei MongoDB funktionieren diese nach dem Master-Slave-Prinzip.
D.h. es existiert ein Replikationsset. Dieses besteht aus einem primären
und beliebig vielen sekundären Knoten. Alle Schreiboperationen gehen nur
an den primären Knoten. Dieser synchronisiert seine sekundären Knoten
erst nach und nach. Das bedeutet, dass die Daten für eine gewisse Zeit
inkonsistent sind. Es kann daher keine Konsistenz zum
Transaktionszeitpunkt garantiert werden wie bei RDBMS. Im schlimmsten
Fall funktioniert die Schreiboperation auf den primären Knoten und
dieser fällt bevor er die Schreiboperation an die sekundären Knoten
weitergegeben hat aus. Dies führt nämlich zu Datenverlust, MongoDB denkt
aber die Operation wurde erfolgreich durchgeführt. Ein Vorteil ist, dass
ein automatischer failover möglich ist. Falls also der primäre Knoten
nicht erreicht werden kann wird ein ehemals sekundärer Knoten zum neuen
primären. Bei Leseoperationen dagegen kann auch auf die sekundären
Knoten zugegriffen werden, um einen Skalierungseffekt zu erhalten. Einen
Flaschenhals stellen also die Schreiboperationen dar, die
Leseoperationen eher nicht. Dies birgt allerdings das Risiko alte
Datenstände zurückzubekommen. Der daraus resultierende erhöhte
Speicherbedarf fällt dank dem Einsatz verteilter Systeme nicht ins
Gewicht. Allerdings sorgen die Replikationen für eine hohe Verfügbarkeit
und dienen auch als Backup der Daten.

Um denn in der heutigen Zeit nicht ungewöhnlichen wachsenden Datenmengen
zu begegnen gibt es automatisches Sharding. Dieses sorgt für die
Verteilung der Daten über mehrere Systeme. Dies wird auch als
horizontale Skalierung bezeichnet. Dies bietet vielfältige Vorteile. Zum
einen verursacht das vertikales Skalieren, also der Einsatz immer
besserer Hardware exponentielle Kosten. Zum anderenen ist der Lokale
Speicher möglicherweise einfach nicht groß genug. Die Komponenten sind
Shards, Config Server und mongos. Jedes Shard entspricht einem oben
beschriebenen Replikationsset. Die Config Server beinhalten die
Metadaten von dem Cluster. Sprich eine Map von den angefragten Daten und
wo sie gespeichert sind. Um Redundanz und Verfügbarkeit zu gewährleisten
muss es drei Config Server geben. Dann gibt es noch die mongos. Diese
werden von der Applikation angesprochen und führen die query Kommandos
aus.

Die Daten werden im sogenannten BSON Format gespeichert und
ausgetauscht.

BASE

\paragraph{Usecases}\label{usecases}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  rapid prototyping
\item
  Leselastige Anwendungen
\end{itemize}

\paragraph{Mongoose}\label{mongoose}

Bei Mongoose handelt es sich um ein Modul für NodeJS. Object Data
Modelling (ODM)

\subsubsection{Express (Michi)}\label{express-michi}

\textbf{Grobschrift, da muss noch viel geändert und zitiert werden.}

Express ist der de-facto Standard für Node.js Webframeworks. Es gibt
sehr viele Alternativen (\href{http://koajs.com/}{koa},
\href{http://hapijs.com/}{hapi},
\href{https://github.com/totaljs/framework}{total.js}), jedoch gibt es
kein anderes Framework, das so viele Benutzer und Mitwirker hat.

Verglichen mit Webframeworks die sich in anderen Sprachen etabliert
haben, ist Express leichtgewichtig und liefert wenig Funktionalität.
Frameworks aus Programmiersprachen wie z.B.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Ruby on Rails in Ruby
\item
  Spring in Java
\item
  Symfony in PHP
\item
  Django in Python
\end{itemize}

liefern Funktionalität für typische Webanwendungen (Sessions, Cookies,
Authentifizierung, Form Handling, Templating, \ldots{}).

Eine Ursache hierfür ist vermutlich, dass es für Express bisher wenig
professionelle Unterstützung gibt.
\href{https://strongloop.com/node-js/training/}{Strongloog}, die Firma
hinter Express, bietet inzwischen Training für Node.js und API
Entwicklung an.

Erweiterte Funktionalität muss bei Express über 3rd-Party Erweiterungen
hinzugefügt werden. Die Wartung dieser Erweiterungen wird dabei nicht
kontrolliert oder von den Entwicklern von Express beeinflusst.

\paragraph{Installation und
Versionierung}\label{installation-und-versionierung}

Die Installation von Express erfolgt über npm (den Node Package Manager)
und macht wenig Probleme. Voraussetzung ist jedoch, dass die
installierte Version von Node, zu der gewünschten Express Version passt.

Im Umlauf befinden sich die Versionen 2, 3, 4 und 5, wobei 2 und 3 als
deprecated markiert wurden und sich 5 noch in aktiver Entwicklung
befindet. Problematisch hierbei ist wieder, dass sämtliche Erweiterungen
für Express zu den entsprechenden Versionen von Express passen müssen.

Entscheidet man sich für vordefinierte MEAN Stacks wie z.B. MEAN.IO oder
MEAN.JS, dann lassen sich einzelne Komponenten nur austauschen, falls
der Ersatz die entsprechenden Versionen von Express und Node
unterstützt. Auf Grund der häufig sehr hohen Anzahl an Erweiterungen ist
dies oft problematisch.

\paragraph{Kernfunktionalität}\label{kernfunktionalituxe4t}

Die Kernfunktionalität von Express ist, wie bereits erwähnt wurde, sehr
beschränkt. Im Prinzip übernimmt Express lediglich das Routing der
Requests auf, vom Entwickler definierte, Callbacks.

Erweiterte Funktionalität wird über Middlewares ermöglicht. Middlewares
können das Request und Response Objekt verändern und weiter- bzw.
umleiten oder terminieren (z.B. falls keine Zugriffsrechte bestehen).

\paragraph{Anwendung}\label{anwendung}

Da Javascript eine Prototyp-basierte Sprache ist, die zumindest vor dem
ES6 Standard kein Klassenkonzept kennt und auf Grund der Art wie Express
die Routes verarbeitet, ist es nicht möglich Controller als Klassen wie
in einer typischen MVC (Model View Controller) Architektur umzusetzen.

Aus Gründen der Übersichtlichkeit und um die Funktionalität zu kapseln
und damit ggf. wiederverwendbar zu machen, haben wir die Controller in
eine Controller ähnliche Struktur gebracht. Die jeweiligen Funktionen
auf den Controllern entsprechen dabei statischen Funktionen anderer
Programmiersprachen (wie bereits erwähnt ermöglich Express nicht
Methoden auf instaziierten Controllern aufzurufen).

\begin{verbatim}
/**
 * Creates a ProjectController
 * @returns {ProjectController}
 */
module.exports = function() {

  'use strict';

  /**
   * Updates an given project and returns the updated object.
   *
   * @param {http.IncomingMessage} req Express Request Object
   * @param {http.OutgoingMessage} res Express Response Object
   * @callback next Callback which calls the next matching route.
   */
  ProjectController.prototype.update = function(req, res, next) {
    // ...
  };

  return new ProjectController();
};
\end{verbatim}

\paragraph{Dependency Injection}\label{dependency-injection}

Da die Funktionalität in Express üblicherweise (vgl.
\href{http://expressjs.com/en/starter/basic-routing.html}{Dokumentation})
via Callbacks realisiert wird, ist es nicht möglich Abhängigkeiten
separat zu verwalten. Die Callbacks von Express kennen lediglich die
Parameter \texttt{req}, \texttt{res} und \texttt{next}. Express
unterstützt Dependency Injection nicht.

Dies hat zur Folge, dass die Erstellung von Objekten vielfach dupliziert
wird und außerdem schlecht testbar ist. Die Abhängigkeiten werden
typischerweise im Callback instanziiert und können somit nicht durch
Mockobjekte ausgetauscht werden.

Es gibt 3rd-Party Erweiterungen wie z.B.
\href{https://github.com/luin/express-di}{express-di} oder
\href{https://github.com/floatdrop/express-dinja}{express-dinja}, diese
waren aber entweder nicht mit unserer Version von Express kompatibel
oder konnten nicht mit unserem Controller-Konzept vereinbart werden.

Eine eigene minimale Implementierung (die von den genannten
Erweiterungen ähnlich implementiert wird) wurde via Middlewares
realisiert. Ein Dependency Injection Container wird dabei an das Request
Objekt \texttt{req} angehängt. Diese Lösung ist nicht optimal und
verletzt u.a. das Single Responsibility Principle
\href{http://www.butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod}{vgl.
The Principles of OOD von Uncle Bob}. Express verhindert jedoch eine
andere Implementierungsweise.

\begin{verbatim}
var dicMiddleware = function(req, res, next) {
  req.dic = {
    subjectRepository: require('../models/SubjectRepository'),
  };
  next();
};
subjectRouter.use('/', dicMiddleware);
\end{verbatim}

Mit dieser Implementierung war es uns möglich die Controller zu testen,
da lediglich Mockobjekte für \texttt{req} und \texttt{res} erzeugt
werden müssen.

\paragraph{Typische Probleme der
Webentwicklung}\label{typische-probleme-der-webentwicklung}

Express unterstützt die häufigst verwendeten Javascript Template Engines
(\href{http://github.com/visionmedia/jade}{Jade},
\href{http://github.com/visionmedia/ejs}{EJS},
\href{http://github.com/visionmedia/haml.js}{Haml}), liefert jedoch
keine eigene Implementierung.

Fair Projects nutzt Express als API und somit finden Templates in der
aktuellen Implementierung keinerlei Verwendung. Ein technischer
Durchstich hat sowohl mit Jade als auch EJS einwandfrei funktioniert.

Authentifizierung und Authorisierung kommen in den meisten klassischen
und modernen Single-Page Anwendungen vor. Express unterstützt weder
Sessions (es gibt aber eine offizielle Erweiterung
\href{https://github.com/expressjs/session}{express-session}), noch
Cookies und damit auch keine Authentifizierung. Die de-facto Erweiterung
zur Authentifizierung ist \href{http://passportjs.org/}{Passport}.

Fair Projects sollte ursprünglich ein externes
Authentifizierungsverfahren von Github, Twitter oder Facebook verwenden.
Die Erweiterungen hierzu von Passport (Passport ist ähnlich wie Express
modular aufgebaut und unterstützt selbst fast keine Verfahren) waren
entweder veraltet und durch neuere ersetzt oder haben sich so
weiterentwickelt, dass die Dokumentation nicht mit der Implementierung
übereinstimmte.

Wir entschieden uns daher für das sog. \texttt{LocalStrategy} Verfahren
also eine eigene Implementierung über z.B. eine Datenbank. Die
Dokumentation von Passport war auch hier nicht immer hilfreich, da viele
externe Plugins (z.B. für Cookies und Session) benötigt werden und die
Dokumentation diese nicht ausreichend beschreibt.

Die aktuelle Implementierung legt Benutzer in der MongoDB Datenbank ab,
verifiziert diese bei (API) Login und speichert die Session via Node.
Benutzer müssen über die API erstellt werden.

\begin{quote}
Hierbei handelt es sich um ein minimalistisches und flexibles
Webframework für Node.js. Es dient der einfacheren Entwicklung moderner
Webanwendungen.
\end{quote}

\begin{quote}
Vorteile - sehr viele Plugins - modularer Aufbau
\end{quote}

\begin{quote}
Nachteile - erlaubt keine schoene Kapselung (Controller Problem also
z.B. hat eine Methode keinen Zugriff auf this) - DI (Dependency
Injection) nur ueber Umweg ueber Middleware moeglich - quick and dirty
\end{quote}

\subsubsection{AngularJS (Markus)}\label{angularjs-markus}

AngularJS ist eines der bekanntesten JavaScript Frameworks welches 2009
von Google veröffentlicht wurde. Es stellt einen Aufsatz zu reinen
HTML-Seiten dar. Klassische Websites setzen meist auf PHP im Backend,
welcher bei jedem Aufruf ein einzelne HTML Webseite generiert. Beim
Durchführen einer Aktion wie beispielsweise dem aufrufen einer
Detailansicht wird ein neuer Request an das PHP Backend durchgeführt und
eine komplett neue HTML Webseite zurück geliefert. Die Webanwendung ist
dabei ausgelegt auf Thin Clients. Der HTML Part davon ist dazu meist
passiv und dient nur zur Anzeige. Im MEAN Stack übernimmt AngularJS
dabei die Aufgabe mehr Logik aus dem Backend in die View zu übernehmen.
Daraus folgt auch, dass es mehr auf Fat Clients ausgelegt ist die viele
Berechnungen und Abläufe erledigen ohne den Anwendungsstatus bei jeder
Aktion neu generieren zu lassen. Dieser generelle Unterschied zu den
klassischen Websites wird unterschieden durch den Begriff ``stateful''.
Der View ist im Gegensatz zu stateless der komplette Status der
Webanwendung bekannt. Die Daten werden dabei im Browser
zwischengespeichert. Zur Synchronisation mit dem Server werden nur die
geänderten Daten in beide Richtungen ausgetauscht. Ein weiteres
Grundprinzip von Angular ist es sogenannte Single-Page-Anwendungen zu
machen. Bei dem Wechseln einer Seite zu beispielsweise einer
Detailansicht wird kein neuer HTTP-Request verschickt, der die Seite
austauscht. Manche Daten sind der Webanwendung bereits bekannt. Ist die
Ansicht zum Beispiel die Übersicht aller Projekte aus dem Fallbeispiel,
werden durch einen Klick auf ein einzelnes Projekt nur die noch
fehlenden Daten angefordert. In der Listenansicht ist der Titel bereits
vorhanden, daher wird nur noch die Beschreibung und die Teilnehmer vom
Backend benötigt. Der komplette Rest der Seite kann dabei unverändert
bestehen bleiben. Dadurch wird bei jedem Request viel Overhead
eingespart.

Um trotz Single-Page-Anwendung auf bestimmte Teile einer Anwendung
mittels URL zugreifen zu können ist ein Routing nötig. Wie in dem
Beispiel TODO zu sehen, wird für jeden einzelnen Pfad der URL angegeben
welches Template verwendet werden soll und welcher Controller. Mit der
.otherwise Funktion kann ein sogenannter Fallback implementiert werden
für einen Aufruf der Hauptseite. Innerhalb der URL können auch gleich
Parameter mit Hilfe von vorangestellten Doppelpunkten angegeben werden
die automatisch die erfolgte Eingabe in der URL im entsprechenden
Controller bereitstellen.

Zur Darstellung der Daten setzt Angular auf das Model View ViewModel
Prinzip (MVVM), das von Microsoft entwickelt wurde. Für diesen
Einsatzweck ist es passender als beispielsweise Model View Controller
(MVC), da das ViewModel ein two-way data-binding zwischen der View und
dem Model ermöglicht. Anders als viele zuerst vermuten, stellt das
ViewModel dabei keinen Ersatz für den Controller dar. Dieser ist zwar
nicht explizit in der Abkürzung genannt, wird aber weiterhin benötigt.
Im Unterschied zu MVVM werden in MVC bei Änderungen im View nicht
automatisch im Model aktualisiert. Das ViewModel hat daher die Aufgabe
jede Änderung in der View auch an das Model zu übertragen und auch
umgekehrt in die andere Richtung. Wird beispielsweise das Model geändert
wird diese Änderung sofort an die View übertragen. Eines der
Alleinstellungsmerkmale von AngularJS unter den JavaScript Frameworks
stellt Dependency Injection dar. Es ist ein Entwurfsmuster mit dem
Abhängigkeiten zentral aufgelöst werden können. Die benötigten Objekte
werden zur Laufzeit zur Verfügung gestellt. Dadurch wird die
Austauschbarkeit erhöht und auch das Testen der Anwendung in dem Teile
durch Mock-Objekte ausgetauscht werden. Näheres dazu dann im Kapitel zur
Testbarkeit.

AngularJS sieht für die Strukturierung folgendes vor: - Module - Models
- View-Templates - Controller - Scopes - Filter - Services Diese
Komponenten können mittels eines Dependency Containers zusammengeführt
werden. Dadurch wird ein modulares Design ermöglicht welches Komponenten
austauschbar macht. Module: Alle zusammengehörenden Komponenten einer
Anwendung werden zur besseren Trennung in Module strukturiert. Auch hier
kommt das Konzept von Dependency Injection zum Tragen. In einem Modul
können wiederum weitere Module eingebunden werden. Models: AngularJS
gibt für Models keine besonderen Klassen vor von denen geerbt werden
müsste. Diese stellen dadurch klassische JavaScript Objekte dar, die
einen Aspekt der Domäne repräsentieren. View-Templates: Das sind in der
Regel Teile von HTML Seiten die mit Platzhaltern oder bestimmten
Angular-Direktiven gefüllt sind. Beispielsweise der Platzhalter
\{\{myVariable\}\} wird im HTML Quelltext durch die Variable aus dem
Controller ausgetauscht. Direktiven erlauben die Erweiterung des HTML um
Tags. Dabei gibt es viele nützliche Funktionen wie beispielsweise
Objekte in einer Schleife durch zu iterieren. Controller: In AngularJS
werden Controller hauptsächlich zur Erstellung von Scopes verwendet. Die
Controller fallen dadurch auch recht kompakt aus. Das heißt für jede
CRUD Operation (Create Read Update Delete) und für jedes Model wird in
AngularJS ein eigener Controller erstellt. Beispielsweise ein
ShowProjectsController. Oftmals werden die Controller auch mit Ctrl
abgekürzt. In unserem Fallbeispiel haben wir uns aber zugunsten der
besseren Verständlichkeit dagegen entschieden. Jede komplexere Logik
sollte in eigenen Services ausgelagert werden und wieder mittels
Dependency Injection eingebunden werden. Scopes: Scopes bündeln die
Daten und Funktionen eines Controllers und ermöglichen die Kommunikation
zwischen Controllern untereinander. Sie beziehen sich immer nur auf
einen bestimmten Abschnitt innerhalb des DOM (Document Object Model)
Filter: Haben wir glaub ich nicht wirklich verwendet? TODO Services: In
unserer Beispielanwendung haben wir beispielsweise den \$resource
Service eingebunden. Damit wird ermöglicht, dass unsere REST
Schnittstelle angesprochen werden kann. Services werden generell als
Singleton instanziiert.

Zur Selektierung von Elementen verwendet AngularJS ein integriertes
jQuery Lite (jqLite). Falls jQuery ebenfalls ausgeliefert wird, wird
auch diese jQuery Version von AngularJS verwendet und nicht jqLite.

Aktuell befindet sich AngularJS in der Version 1.4.8. Es ist jedoch
schon seit längerer Zeit bekannt, dass die nächste große Version 2.0
nicht abwärtskompatibel sein wird mit Version 1.x. Version 2.0 befindet
sich im Moment noch im Beta Stadium und es ist noch nicht abzusehen wann
es veröffentlicht wird. Aus diesem Grund haben wir uns auch dagegen
entschieden auf Version 2.0 zu setzen. Je nach geplanter Lebensdauer der
Webanwendung sollte entschieden werden ob ein Einsatz in Frage kommt.

\subsubsection{Node.js (Marinus)}\label{node.js-marinus}

\paragraph{Entstehung}\label{entstehung}

Ryan Dahl stellte 2009 Node.js als serverseitige Plattform für
Netzwerkanwendungen vor. Anfangs nur für Linux Betriebssysteme geeignet,
wurde in den folgenden Jahren auch die Kompatibilität zu Mac und Windows
hergestellt. Stetig anwachsende Entwicklerzahlen
(https://github.com/nodejs/node/graphs/contributors) sowie Suchanfragen
(https://www.google.de/trends/explore\#q=nodejs) lassen auf die
wachsende Bedeutung schließen. Im Januar 2014 wurde Node.js von
Thoughtworks Technologie Radar erstmals für den Unternehmenseinsatz
geeignet eingestuft
(https://www.thoughtworks.com/radar/platforms/node-js).

\paragraph{Konzepte}\label{konzepte-1}

Node.js ist quelloffen nach MIT lizenziert. Es ist somit möglich den
Quellcode einzusehen, sowie aktiv an der Entwicklung von Node.js
mitzuwirken. Als Basis wird Googles Java-Script-Implementierung V8
verwendet. V8 wurde ursprünglich für den Internet-Browser Chrome
entwickelt und stellt eine Just-in-time-Kompilierung des JavaScript-Code
in nativen Maschinen-Code zur Verfügung. Erst diese Technologie
ermöglicht den performanten serverseitigen Einsatz von JavaScript.

Zentrales Konzept ist die asynchrone, nicht blockierende Verarbeitung
von Ein- und Ausgabe mittels des ``Event-Loop'' Konzepts. Im Gegensatz
zum weiterverbreiteten Ansatz für jede Verbindung einen eigenen Thread
zu erstellen, werden dabei alle Verbindungen über einen einzigen Thread
verwaltet. Um dennoch mehrere Verbindungen (nahezu) gleichzeitig
abarbeiten zu können, muss die Abarbeitung einzelner Anfragen asynchron
beziehungsweise nicht blockierend erfolgen. Teure Operationen, wie
beispielsweise I/O Zugriffe, werden (bei sinnvoller Umsetzung) dabei
nicht wartend ausgeführt. Ist eine Operation abgeschlossen wird ein
Signal abgegeben und die Event-Loop führt im nächst möglichen Schritt
die Ergebnis Abarbeitung durch (Callback).

Node.js ist modularisiert aufgebaut. Neben der Möglichkeit Erweiterungen
durch eigene Module, beziehungsweise Module von Dritten hinzuzufügen,
ist auch der komplette Kern von Node.js in Module gegliedert. Einige
dieser Module werden aus Performanz Gründen in binär-Code für die
jeweiligen Plattformen zur Verfügung gestellt. Seit 2011 steht mit
``npm'' ein Tool zur Verwaltung der Pakete bereit. Mit npm können Pakete
installiert sowie verteilt werden, wobei auch Abhängigkeiten aufgelöst
werden.

Basierend auf diesen Erkenntnissen werden im folgenden die Vor- und
Nachteile der eingesetzten Konzepte vorgestellt.

\paragraph{Stärken}\label{stuxe4rken}

Als stärkstes Verkaufsargument ist bei Node.js eindeutig der
Ressourcen-schonende Umgang mit Webverbindungen hervorzuheben. Durch das
Verwenden eines einzigen Threads entfällt der sonst notwendige Overhead
der für jede Verbindung nötig wäre. Dadurch ist es Möglich eine hohen
Anzahl von Verbindungen gleichzeitig zu halten. Anwendungen deren
Hauptaufgabe die Ein- und Ausgabe von Daten ist, profitieren hiervon
besonders.

Noch intensiver schlägt sich dies beim Einsatz von Websockets nieder. Da
bei Websockets die Verbindungen dauerhaft aufgebaut bleiben und nicht
mit Absenden der Antwort freigegeben werden können, ergibt sich die
Notwendigkeit viele Verbindungen gleichzeitig halten zu können.

Heutzutage setzten viele Anwendungen auf eine REST-basierte
Schnittstelle die Daten im JSON-Format verarbeitet. Auch FairProjects
ist nach diesem Prinzip aufgebaut. Node.js kann hier durch die
sprachliche Unterstützung von JSON durch JavaScript profitieren. JSON
Daten können dadurch einfach und effizient verarbeitet werden.

Die große Community um JavaScript und Node.js ermöglicht es einerseits
zu vielen Themen Diskussionen und Informationen zu finden anderseits
aber auch auf viele bestehende Lösungen zurückzugreifen. Über den
Paketmanager npm ist es Möglich eine Vielzahl von freien Erweiterungen
zurückzugreifen (\textgreater{}220 000, Stand: Januar 2015).

Gerade dies bringt jedoch auch Nachteile mit sich, worauf im Folgenden
eingegangen wird.

\paragraph{Schwächen}\label{schwuxe4chen}

Wie im vorherigen Absatz erwähnt, gibt es viele freie Erweiterungen,
problematisch ist hierbei jedoch, dass die meisten dieser Erweiterungen
nur über einen kurzen Zeitraum weiterentwickelt und gepflegt werden.
Wenn Module dann noch Abhängigkeiten zu bestimmten Versionen von anderen
Modulen haben, wird dies zum Problem. Dies verhindert oftmals die
Möglichkeit Module auf deren neuesten Stand zu bringen da gleichzeitig
verschiedene Versionen eines Moduls benötigt werden. Schlechte Wart- und
Erweiterbarkeit sind dann die Folgen.

Ähnlich verhält es sich mit Code-Beispielen sowie Anleitungen durch die
Community. Es gibt hierzu zwar reichlich Informationen, jedoch nur sehr
wenige behandeln Szenarien die über einfache Beispiele hinausgehen.

Aus technischer Sichtweise kann unter den Nachteilen die schlechte
horizontale Skalierbarkeit aufgeführt werden. Durch den Single-Thread
Ansatz kann nicht durch hinzunehmen weiterer Prozessoren skaliert
werden.

\paragraph{Callback}\label{callback}

Callbacks sind in Node.js ein so zentrales Element dass hierfür ein
eigener Absatz gewidmet wird. Um Node.js zu beherrschen zu können ist es
wichtig die Konzepte und Schwierigkeiten von Callbacks zu verstehen.
Callbacks sind dabei keine Erfindung von Node.js sondern ein Teil von
JavaScript.

Callbacks sind im wesentlichen Funktionen die asynchron oder zu einem
späteren Zeitpunkt ausgeführt werden. Dies ermöglicht es, auf das
Ergebnis einer anderen Funktion zu warten, ohne dabei blockierend zu
arbeiten.

\begin{verbatim}
var filesystem = require('fs');

filesystem.readFile('test.txt', function handleFile(error, fileContents) {
  doSomething();
});

otherFunction();
\end{verbatim}

In diesem Codebeispiel wird eine Datei eingelesen um aus dieser etwas
auszulesen. Um nicht auf den Zugriff auf das Dateisystem blockierend
warten zu müssen, wird hier \texttt{handleFile} als Callback verwendet.
Die Funktion wird aufgerufen sobald die Datei geladen wurde. Da der
Zugriff auf das Dateisystem ein sehr zeitintensiver Vorgang ist, wird
wahrscheinlich die Funktion \texttt{otherFunction} noch vor
\texttt{handleFile} ausgeführt.

Welche Schwierigkeiten ergeben sich dadurch? Zum einen muss beim lesen
von Code darauf geachtet werden, dass nicht wie beim prozeduralen
Vorgehen Zeile für Zeile nacheinander ausgeführt wird. Der Kontrollfluss
ist dadurch schwieriger Nachzuvollziehen. Des Weiteren entstehen so
leicht tiefe Verschachtelungen.

\begin{verbatim}
doFirstThing(function() {
  doSecondThing(function() {
    doThirdThing();
  });
}); 
\end{verbatim}

Dies wäre eine naive Implementierung bei der drei Funktionen
hintereinander ausgeführt werden. Es braucht nicht viel
Vorstellungskraft dass bei etwas mehr auszuführenden Schritten
(beispielsweise Fehlerbehandlung) so schnell unübersichtlicher Code
entsteht. Dieses Problem wird auch als ``Callback-Hell'' bezeichnet und
vor allem von Anfängern oft begangen.

Welche Möglichkeiten gibt es diese tiefen Verschachtelungen zu umgehen?
Im nachfolgenden werden zwei Ansätze vorgestellt um der
``Callback-Hell'' zu umgehen.

\emph{Sprechende Funktionen}

Um den Code leserlich zu gestalten werden bei diesem Ansatz die Callback
Funktionen nicht wie im obrigen Beispiel anonym definiert, sondern in
einer Variable mit aussagekräftiger Bezeichnung zugewiesen. Für das
bisherige Beispiel würde dies folgendermaßen umgesetzt werden:

\begin{verbatim}
doFirstThing(afterFirstThing);

function afterFirstThing() {
  doSecondThing(afterSecondThing);
}

function afterSecondThing() {
  doThirdThing();
}
\end{verbatim}

So können die tiefen Versdchachtelungs-Ebenen verhindert werden. Jedoch
wird bei komplexeren Szenarien mit mehreren Verzweigungen der
Programmablauf nur schwer erkennbar und unübersichtlich.

\emph{Promises}

Um hier ein lesbareres Konzept zu haben, werden Promises verwendet. Eine
ausführliche Erklärung dieses Konzept würde an dieser Stelle zu weit
gehen, jedoch wird im Folgenden kurz der Aufruf von Funktionen die ein
solches ``Promise-Objekt'' zurückgeben erläutert.

Durch aneinander gekettete Aufrufe von Funktionen (Chaining) können für
verschiedene Ereignisse auszuführende Funktionen Registriert werden. So
kann mit der Funktion \texttt{.then()} ähnlich eines Callbacks eine
Funktion registriert werden, die nach erfolgreichem Beenden ausgeführt
wird. Im Unterschied dazu kann jedoch die Fehlerbehandlung in einer
eigenen Funktion abgehandelt werden (\texttt{.catch()}). Mit diesem
Konzept können Abläufe lesbar programmiert werden. Für vorheriges
Beispiel ergibt sich folgender Code:

\begin{verbatim}
doFirstThing()
.then(function doSecondThing() {
  //Code here
  }
).then(function doThirdThing() {
  // Code here
  }
);
\end{verbatim}

Um dies zu ermöglichen muss eine Funktion jedoch ein Promise Objekt
zurückgeben. Die Details hierzu werden nicht behandelt, jedoch ist
anzumerken dass viele Module dieses Konzept nicht anbieten. In diesem
Fall kann das Konzept der Promises nicht benutzt werden.

\subsubsection{Testbarkeit (Michi)}\label{testbarkeit-michi}

Viele Javascript Projekte und darunter u.a. AngularJS werben damit
leicht testbar zu sein
\href{https://docs.angularjs.org/guide/unit-testing}{AngularJS Developer
Guide - Unit Testing}.

Um die Qualität einer Single-Page Anwendung zu sichern, gilt es folgende
Ebenen zu testen:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Frontend Unit Tests
\item
  Server Unit Tests
\item
  Integrations/E2E (End-to-End) Tests
\end{itemize}

Wir möchten die Testbarkeit eines MEAN Stacks nicht nur mit den in
Javascript üblichen Praktiken vergleichen, sondern sprachübergreifende
Erwartungen an die Testbarkeit einer verteilten Anwendung stellen.

Während der Vorbereitung auf dieses Projekt fanden wir keine Quellen
oder Beispielimplementierungen, welche den gesamten Testprozess des MEAN
Stacks beschreiben. Darüber hinaus haben viele häufig verwendete
Erweiterungen keine oder nur unzureichende Testabdeckung.

\paragraph{Frontend Unit Tests}\label{frontend-unit-tests}

AngularJS unterstützt das Testframework
\href{http://jasmine.github.io/}{Jasmine} und die meisten anderen
bekannten Javascript Testframeworks über 3rd-Party Erweiterungen. Wir
haben uns auf Grund der mangelnden Dokumentation für das offiziell
unterstützte Jasmine entschieden.

In der Dokumentation von AngularJS befindet sich ein Kapitel zu Unit und
E2E Testing und damit war es relativ einfach Tests zu schreiben.
Vermutlich auf Grund der Unterstützung vieler verschiedener
Testframeworks muss man für das Testen der verschiedenen Komponenten
(Controller, Services usw.) immer den Bootstrap Code von Hand schreiben.
Dies ist nicht nur aufwändig, sondern auch fehlerträchtiger, als wenn
AngularJS nur ein Testframework unterstützen würde und die
Funktionalität für das Testen ihrer Komponenten vorgeben.

Da die Tests abhängig von der jeweiligen Browserumgebung sind, müssen
die Tests in verschiedenen Browsern ausgeführt werden (das Kapitel
\url{Testautomatisierung} beschriebt Alternativen). Fair Projects
verwendet \href{http://karma-runner.github.io/0.13/index.html}{Karma} um
die Tests automatisiert auf verschiedenen Browsern auszuführen.

TODO evtl. hier noch auf Mockproblematik mit Jasmine verweisen oder auf
das nächste Kapitel verweisen

\paragraph{Backend Unit Tests}\label{backend-unit-tests}

In der Dokumentation von Express wird der Testvorgang oder generell
Testbarkeit nicht behandelt. Wie bereits im Kapitel zu Express genannt,
ist es mit der eigentlichen Architektur von Express auch nur sehr schwer
möglich Unit Tests zu schreiben, da Callbacks verwendet werden und keine
Dependency Injection mitgeliefert wird.

Durch die bereits beschriebenen Änderungen konnten wir zum einen unsere
Datenbankschicht (Repositories) mit Mockobjekten austauschen und durch
die Extraktion der Callbacks in eigene Funktionen war es möglich
Controller zu testen.

Auf der Suche nach empfohlenen Praktiken hat sich herausgestellt, dass
im Backend selten ausreichend getestet wird. Die vermeintlich schnelle
Entwicklung mit Javascript führt damit zu ungetestem Code, welcher
vermutlich zu Wartungsproblemen führt.

Wie auch bereits für die Frontend Unit Tests, benutzen wir Jasmine als
Testframework. Es gibt andere bekannte Testframeworks wie z.B.
\href{https://mochajs.org/}{mocha}, aber da Jasmine der Standard für
AngularJS ist, macht es Sinn dieses auch für das Backend zu verwenden um
keine weitere unnötige Abhängigkeit in das Projekt einzuführen.

Im Vergleich zu den Frontend Tests ist es leichter die Tests zu
automatisieren, da sie wie von anderen Sprachen gewohnt auf der Console
(\href{https://github.com/mhevery/jasmine-node}{jasmine-node}) oder in
der Entwicklungsumgebung ausgeführt werden können.

In Node werden sämtliche externe Aufrufe asynchron ausgeführt. Dies
führt dazu, dass das schreiben von Tests im Vergleich zu z.B. Java
relativ aufwändig ist, da die Tests trotz Mocking der externen Quellen
(in unserem Fall z.B. das \texttt{SubjectRepository}) mit Asynchronität
arbeiten müssen.

Für Fair Projects benutzen wir das Promise Framework
\href{http://bluebirdjs.com/}{bluebird}. TODO Promises lösen das Problem
der verschachtelten Callbacks (die sog. Callback Hell) und sind zudem
testbar, da man ein Promise erstellen kann, das bereits erfüllt wurde.

Trotzdem ist es notwendig ein Promise Objekt für das Mockobjekt zu
erstellen. Die Tests werden dann so geschrieben, dass die Testbedingung
(assert) erst geprüft wird, wenn das Promise aus dem Mockobjekt erfüllt
ist.

\paragraph{E2E Tests}\label{e2e-tests}

Bei End-to-End (oder auch: Systemtests) wird das gesamte System mit
allen Abhängigkeiten getestet. In anderen Sprachen wird dabei z.B. die
Bedienung der Benutzeroberfläche via
\href{http://www.seleniumhq.org/}{Selenium} automatisiert.

Für Anwendungen die AngularJS als Frontend Framework verwenden bietet
sich \href{http://www.protractortest.org/}{Protractor} an. Protractor
wurde von Google entwickelt
\href{http://googletesting.blogspot.de/2014/11/protractor-angular-testing-made-easy.html}{Quelle}
und als Open-Source Projekt frei zur Verfügung gestellt.

Tests auf der Benutzeroberfläche haben häufig das Problem, dass die
Tests sehr instabil gegenüber Veränderungen sind. Mit Protractor kann
man sich auf AngularJS spezifische Attribute beziehen, welche sich nicht
ändern, wenn die Darstellung verändert wird. Ebenso ermöglich Protractor
die inneren Zustände abzufragen (also die Models in AngularJS) und nicht
nur die grafische Darstellung des Ergebnisses (die sich vermutlich
häufiger ändert).

E2E Tests waren somit leichter zu entwickeln und stabiler gegenüber
Änderungen, als E2E Tests wie man sie aus anderen Frameworks oder
Sprachen kennt. Dies ist jedoch kein Argument für den MEAN Stack im
gesamten, sondern jediglich für AngularJS als Frontend Framework.

Für Fair Projects haben wir die API nicht explizit getestet, da dies
auch über die E2E Tests abgedeckt wird. Manche Anwendungen verzichten
auf Unit Tests (vermutlich auf Grund der im vorigen Kapitel
beschriebenen Problematik) und testen die Endpunkte der Express API.
\href{https://github.com/visionmedia/supertest}{SuperTest} ist eine
Erweiterung für Jasmine und erlaubt es für REST Anfragen die Antworten
zu testen (z.B. hinsichtlich Status Code oder Body).

\paragraph{Testabdeckung}\label{testabdeckung}

Testabdeckung kann für alle oben genannten Testframeworks (sogar für E2E
Tests die mit Protractor geschrieben wurden, dies ist jedoch nur bedingt
sinnvoll und kann eine Abdeckung durch Unit Tests nicht ersetzen) via
\href{https://gotwarlost.github.io/istanbul/}{Istanbul} erfasst werden.

Istanbul speichert die gesammelten Informationen als \texttt{.lcov}
Datei (sowie in andere Formate wie z.B. Plaintext oder HTML), welche
wiederum kombiniert werden können um eine Aussage über die Testabdeckung
von Front- und Backend treffen zu können.

Die Testabdeckung kann von allen üblichen Continuous Integration Servern
wie Jenkins oder Travis analysiert werden. Darüber hinaus gibt es
Webservices wie
\href{https://codeclimate.com/github/mihaeu/fair-projects/coverage}{Code
Climate}, welche sich auf Trendanalysen von Testabdeckung spezialisiert
haben. Diesen Service verwendet auch Fair Projects.

\paragraph{Testautomatisierung}\label{testautomatisierung}

Da es sich bei Travis um ein Open-Source Projekt handelt verwenden wir
Travis CI als Continuous Integration Server.

Dieser führt sowohl Front- als auch Backend Unit Tests bei Aktivität im
Repository aus. Die Backend Unit Tests können dabei fehlerfrei
ausgeführt werden, aber Frontend und E2E Tests sind stark abhängig von
den unterschiedlichen Browsern.

\href{http://phantomjs.org/}{PhantomJS} kann verwendet werden ohne einen
echten Browser zu starten. Frontend Unit Tests werden auf diese Weise
von Travis gestartet, allerdings kann dies zu verfälschten Ergebnissen
(v.a. false negatives, also fehlschlagende Tests die in echten Browsern
funktionieren) führen. PhantomJS hat es uns allerdings nicht ermöglich
unsere Protractor Tests auf dem CI Server ausführen zu lassen.

Es ist möglich mit xvfb (X Virtual Framebuffer zur Emulation von
Displays an Servern die kein Display haben) ein Display zu emulieren.
Auch hier würde sich ein interner CI Server mit Display und echter
Browserumgebung anbieten um korrekte Testergebnisse zu bekommen.

\subsubsection{Werkzeuge (Michi)}\label{werkzeuge-michi}

Die folgenden Kapitel diskutieren die verschiedenen Werkzeuge, die bei
der Entwicklung von Fair Projects verwendet wurden und Alternativen,
falls vorhanden.

\paragraph{Dependency Management}\label{dependency-management}

In jeder Node Installation ist der bereits erwähnte Node Package Manager
npm integriert. Dieser wird zur lokalen und globalen Installtion von
Node Anwendungen und Bibliotheken verwendet.

Für Abhängigkeiten im Frontend Bereich hat sich
\href{http://bower.io/}{Bower} durchgesetzt.

Um die Installation zu erleichtern führt npm bei der Installation der
Abhängigkeiten anschließend \texttt{bower\ install} aus.

\paragraph{Build Management}\label{build-management}

Build Management ist v.a. aus kompilierten Sprachen wie C oder Java
bekannt. Bekannte Vertreter hierfür sind z.B. Make, Ant, Maven oder
Gradle. Aber auch in Skriptsprachen wie Ruby (Rake), Python (PyMake),
PHP (Phing) oder Javascript ist Build Management erforderlich.

Die hier vorgestellten Werkzeuge zum Build Management sind nicht nur für
MEAN Anwendungen geeignet, sondern finden in den meisten Webanwendungen
Verwendung im Frontend Bereich.

Einfache Skripte können via npm ausgeführt werden und werden automatisch
von den meisten Continuous Integration Servern unterstützt. Travis z.B.
führt automatisch \texttt{npm\ install} und \texttt{npm\ test} aus.

Für komplexere Aufgaben ist npm nicht geeignet und i.d.R. leitet npm auf
ein spezielles Build Management Werkzeug weiter.

Fair Projects verwendet \href{gruntjs.com}{Grunt}, da es hierfür die
meisten Erweiterungen gibt. \href{http://gulpjs.com/}{Gulp} ist ein
weiterer bekannter Vertreter und vertritt den Ansatz Code over
Configuration.

Grunt automatisiert bei Fair Projects folgende Aufgaben:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  statische Analysen der Javascript Dateien
\item
  komprimieren und kombinieren der Frontend Assets
\item
  startet den Node Server
\item
  ausführen aller Tests
\item
  erneutes Laden der Anwendung im Browser
\end{itemize}

Bei Änderungen an Projektdateien werden die nötigen Aktionen automatisch
erneut ausgeführt. So führen z.B. Änderungen am Frontend dazu, dass die
Anwendung im Browser neu geladen wird und Änderungen im Backend starten
zusätzlich den Server neu.

Sehr viele der Programme v.a. bzgl. den Frontend Assets sind in
Javascript geschrieben worden. Die Grunt Erweiterungen selbst sind meist
nur Wrapper für ein Konsolenskript (z.B.
\href{https://github.com/addyosmani/grunt-uncss}{grunt-uncss} für
\href{https://github.com/giakki/uncss}{uncss}). Die gleiche
Funktionalität für z.B. ein Maven Plugin zur Verfügung zu stellen wäre
wenig Aufwand und somit könnte auch ein Java Projekt mit nur einem
Werkzeug zum Build Management auskommen.

Das Build Management ist somit kein reines Argument für MEAN, da die
meisten Aufgaben die von Grunt erledigt werden das Frontend betreffen
und dies Browser-bedingt immer Javascript ist.

\paragraph{Qualitätssicherung}\label{qualituxe4tssicherung}

Wie bereits im vorigen Kapitel erwähnt, verwendet Fair Projects
statische analysen um den Javascript Code zu prüfen. Ein klarer Vorteil
von MEAN ist, dass die gleichen Anforderungen für das Front- und Backend
gelten.

Ein klarer Nachteil von Javascript ist es, dass es sehr wenig Werkzeuge
zur Qualitätssicherung gibt. \href{http://jscs.info/}{JSCS} und
\href{http://jshint.com/}{JSHint} prüfen den Code hinsichtlich
Formatierung und einfachen Programmier-Regeln (z.B. Vergleich mit
\texttt{===} anstatt \texttt{==} oder Anweisungen die nicht erreicht
werden können).

Werkzeuge welche Architektur, Abhängigkeiten oder ähnliches prüfen gibt
es nicht. Auch bei der Suche nach Speicherlöchern muss man auf
Werkzeugunterstützung verzichten.

Viele Firmen wie Google oder Microsoft benutzen Technologien (GWT) oder
Sprachen (Typescript, Dart) die typsicher sind oder mehr Struktur bieten
und auf Javascript kompiliert werden können (siehe Ausblick).

\paragraph{Entwicklungsumgebung}\label{entwicklungsumgebung}

Die im vorigen Kapitel genannten Eigenschaften von Javascript führen
leider dazu, dass die Entwicklungsumgebungen für Javascript nicht die
gleiche Funktionalität wie bei anderen Sprachen bereitstellen kann.

Selbst Autovervollständigung oder Dokumentation kann häufig nicht
richtig angezeigt werden, da es in Javascript mehrere Varianten gibt
Dateien einzubinden (\texttt{require}). Bei einer Sprache wie Javascript
die selbst nur eine kleine API besitzt und viel auf den Einsatz von
Fremdbibliotheken aufbaut, erschwert dies die Entwicklung.

Werkzeuge wie Grunt, JSHint usw. werden allerdings einwandfrei
unterstützt und ermöglichen ohne den Einsatz der Konsole zu arbeiten.

\paragraph{Debugging und Profiling}\label{debugging-und-profiling}

Sehr angenehm hingegen waren unsere Erfahrungen mit Profiling und
Debugging. Da sowohl Mozilla als auch Google viel Javascript in ihren
Anwendungen verwenden besitzen beide Browser gute Debugger. Die Debugger
implementieren die typischen von einem Debugger erwarteten Funktionen
wie Breakpoints, Watches usw.

Für Debugging im Backend gibt es die Möglichkeit dies auch über den
Browser (\href{https://github.com/node-inspector/node-inspector}{Node
Inspector})durchzuführen oder aber auch über Konsole oder
Entwicklungsumgebung.

Node Inspector und die Entwicklungsumgebung Webstorm verfügen ebenso
über einen Profiler mit dem CPU und Speicherverbraucht überwacht werden
können.

\href{https://developer.chrome.com/devtools/docs/javascript-memory-profiling}{Quelle}
\href{https://developer.chrome.com/devtools/docs/cpu-profiling}{Quelle}

\subsubsection{Auslieferung (Michi)}\label{auslieferung-michi}

\paragraph{Installation}\label{installation}

Die einzige benötigte Abhängigkeit auf einem aktuellen Linux Server sind
Node und MongoDB. Beide können in der Regel über den Paketmanager der
Linux Distribution installiert werden. Alternativ reicht es meist die
geüwnschte Node Version als Binärdatei herunterzuladen.

Die Installation von Fair Projects ist damit einfach auszuführen:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{git} \NormalTok{clone https://github.com/mihaeu/fair-projects}
\KeywordTok{cd} \NormalTok{fair-projects}

\CommentTok{# lädt Front- und Backend Abhängigkeiten}
\KeywordTok{npm} \NormalTok{install}

\CommentTok{# Produktion: startet den Server}
\KeywordTok{node} \NormalTok{server.js}

\CommentTok{# Entwicklung: startet Tests etc.}
\KeywordTok{npm} \NormalTok{install --global grunt-cli}
\KeywordTok{grunt}
\end{Highlighting}
\end{Shaded}

Im Vergleich zu anderen Sprachen wie Python oder PHP ist die
Auslieferung einer MEAN Anwendung schwerer, aber vom Aufwand
vergleichbar mit Java. Viele Webhosts unterstützen Node noch nicht, aber
da größere Anwendung ohnehin einen eigenen Server mit Administration
benötigen ist dies kein Kritikpunkt. Beliebt für die Auslieferung sind
sog. PaaS (Plattform as a Service) Anbieter wie z.B. Heroku oder
EngineYard. Häufiges Ausliefern der Anwendung ist damit einfach, jedoch
steigen die Kosten bei hoher Last, so dass sich eigene Server ab einer
bestimmten Größe lohnen.

Darüber hinaus benötigt man Monitoring um Node beim Absturz oder falls
es zu einem Memoryloch kam, automatisch neu zu starten.

\paragraph{Docker}\label{docker}

Fair Projects nutzt Docker um das Setup der verschiedenen Komponenten am
Server zu automatisieren (Provisioning). Die Anwendung wird beim
Anbieter Digital Ocean auf einem einfachen Server ausgeführt.

Der Vorteil an diesem Ansatz ist zum einen, dass die Konfiguration der
Software kompatibel zur Version der Software ist, da beides versioniert
wird. Ebenso ist es sehr einfach die Anwendung horizontal (und
theoretisch auch) vertikal zu skalieren.

Die Kombination aus MongoDB und Node lässt sich somit leicht skalieren
(falls Sessions in der Datenbank gespeichert werden) und bei steigender
Last können auf Mausklick neue Instanzen gestartet werden.

\subsubsection{Security: Das KO-Kriterium für den Produktiveinsatz
(Marinus)}\label{security-das-ko-kriterium-fuxfcr-den-produktiveinsatz-marinus}

Immer wenn neue Technologien sich verbreiten stellt sich die Frage, wie
sicher sind diese gegen fremde Angriffe. Gerade bei bei einem Stack für
die Server-Client Kommunikation über das Internet steht dies besonders
im Fokus. JavaScript im Browser stand gerade in der Vergangenheit (und
auch heute) oft in Verbindung mit erfolgreichen Angriffen in der Kritik.
Im Nachfolgenden wird auf bekannte Angriffsvektoren speziell für den
MEAN Stack eingegangen.

\paragraph{JavaScript}\label{javascript}

Wenn über die Angreifbarkeit eines MEAN Stacks gesprochen wird, können
die Einflüsse der drunterliegenden Sprache nicht ignoriert werden.
JavaScript ist von sich aus nicht unsicherer als andere Sprachen. Die
fehlende Typisierung verhindert es jedoch statische Analysen im Umfang
von typisierten Sprachen zu erstellen. Aus diesem Grund ist die
Unterstützung durch Entwicklungsumgebungen oder externen
Überprüfungsprogrammen prinzip-bedingt eingeschränkt.

\paragraph{Node.js}\label{node.js}

Node.js benutzt wie bereits erwähnt für alle Verbindungen lediglich
einen Thread. Angreifer versuchen dieses Prinzip zu nutzen. Durch
provozieren von ungefangenen Fehlern, kann so ein kompletter Service zum
Absturz gebracht werden. Dadurch dass alle Verbindungen den gleichen
Thread nutzen, hat dies einen sehr viel größeren Einfluss als bei
Architekturen, die pro Verbindung einen eigenen Thread nutzen.

Werden Benutzereingaben nicht ausreichend validiert, kann ein Absturz
des kompletten Services die Folge einer bösartigen Anfrage sein. Die
Gefahr durch ``Denial of Service'' (DoS) Angriffe ist deshalb stark von
der Validierung abhängig.

Auch für DoS Angriffe genutzt werden Anweisungen die blockierend im
Haupt Thread ausgeführt werden, jedoch zeitintensiver als vorhergesehen
sind. Beispiel hierfür ist das Validieren von Regulären Ausdrücken.
Durch geschickt gewählte Zeichenketten, kann so die benötigte Zeit zum
Validieren in die Höhe getrieben werden.

Die JavaScript Funktion `eval' wurde schon lange vor Node.js als
sicherheitsbedenklich eingestuft. Die Funktion ist jedoch auch auf
server-seitigen Javascript benutzbar. Mit `eval' kann ein String als
Code behandelt und ausgeführt werden. Werden damit Benutzereingaben
verarbeitet, kann dies als mächtiges Einfallstor genutzt werden. Der
unsichere Code muss dabei nicht selbst geschrieben sein, sondern kann
durch das Einbinden von fremden Modulen unbeabsichtigt eingeführt
werden.

Ähnlich verhält es sich mit der Möglichkeit von Node aus Bash Scripte zu
starten. Mit der Methode 'exec()' des ``child\_process'' Moduls kann
jeglicher Code ausgeführt werden. Hier sollte besser auf die Methode
`execFile()' zurückgegriffen werden.

\paragraph{Express}\label{express}

Zu Express selbst sind bisher nur wenige Angriffe bekannt. Dies liegt in
erster Linie am beschränkten Funktionsumfang. Zu Angriffsszenarien wie
Cross Site Request Forgery und ähnlichen Themen müssen eigener Code oder
andere Bibliotheken verwendet werden.

\paragraph{NPM}\label{npm}

Der Packet Manager von Node.js ist eines der kritischsten Punkte einer
MEAN Anwendung. Mit npm ist es einfach möglich fremde Pakete in ein
Projekt einzubinden. Dieses Feature wird deshalb oft genutzt. Bei
unvorsichtigem Vorgehen ergeben sich so jedoch mehrere
Angriffsmöglichkeiten.

Zu erst wäre hier das unreflektierte übernehmen von fremden Code
aufzuführen. Durch die von Node forcierte Philosophie möglichst viele
kleine Module zu erstellen, und öffentliche Module zu nutzen, ist es nur
schwer möglich den kompletten fremden Code zu übersehen. Durch die tiefe
Verschachtelung in den Abhängigkeiten von fremden Modulen wird dies bei
Änderungen, beispielsweise Updates fast unmöglich.

Zu letzt sei noch die Möglichkeit erwähnt, Skripte bei der Installation
von Paketen mittels npm auszuführen. Bei jedem Paket kann definiert
werden was vor der Installation ausgeführt werden soll. Werden diese
Anweisungen nicht vorher überprüft können so beliebige Anweisungen
ausgeführt werden. Im Januar 2015
(https://blog.liftsecurity.io/2015/01/27/a-malicious-module-on-npm)
wurde auf diese Weise ein Paket veröffentlicht was folgende Anweisung
beim installieren ausführt:

\begin{verbatim}
rm -rf /*
\end{verbatim}

Das Ergebnis ist die Löschung des eigenen Systems.

So viele Vorteile der Paketmanager auch bietet, muss er doch mit hoher
Vorsicht behandelt werden.

\subsection{MEAN Frameworks (Fabian)}\label{mean-frameworks-fabian}

\subsubsection{Mean.io}\label{mean.io}

Mean.io ist ein Framework, dass auf die Kombination der verbreiteten
Technologien MongoDB, Node.js, Angular.js und Express.js setzt. Es wurde
von dem Freelancer Amos Haviv in Kooperation mit dem Unternehmen
Linnovate als Open Source veröffentlicht. Weiterhin sollte Amos Haviv
dieses für die Community pflegen. Es zeichnet sich dadurch aus, dass es
eines der ersten Frameworks ist, die auf dem MEAN Stack basieren. Nicht
zuletzt dadurch hat Mean.io eine beachtliche Community.

\subsubsection{Mean.js}\label{mean.js}

Durch einen Interessenskonflikt zwischen Amos Haviv und dem Unternehmen
Linnovate entschied sich dieser ein neues Framework namens Mean.js
aufzubauen und sich von Linnovate zu trennen. Dieses entstand im Februar
2014 aus einem fork von Mean.io. Da Mean.io Open Source ist war dieses
Vorgehen rechtlich möglich. Das Ziel ist die Entwicklung eines produktiv
einsetzbaren Frameworks. Obwohl alle Technologien von MEAN einzeln
betrachtet produktiv einsetzbar sind, erweist sich die Kombination
dieser als problematisch.

Die Entwickler haben aus den Problemen von Mean.io, zum Beispiel dem
nicht vorhandenen Versions Schema gelernt. Was wurde gegenüber Mean.io
geändert?

Modularity - Support von MVC Modulen - Angular.js, Support vertikaler
Module

Legacy Support - Versions Schema eingeführt

Community - Besserer Support für MEAN Entwickler - Twitter, Facebook,
Google Gruppe, IRC-Channel (real-time support)

Zukunftsziele - Mean Kern verbessern und Fehler beheben (Bug fixing) -
Building companion modules to extend MEAN with different web application
features - Building a Yeoman Generator - Admin panel for managing MEAN
application

\subsubsection{Meteor.js}\label{meteor.js}

Ein weiteres interessantes Open-Source Framework ist Meteor.js. Die
Initiale Veröffentlichung dieses Frameworks war 2012. Es ist für die
Entwicklung von Echtzeit Web Anwendungen gedacht. Es handelt sich
hierbei um eine client-server Plattform. Meteor.js setzt auf die
Technologien MongoDB, Node.js und Angular.js. Die Aktuelle Version ist
die 1.2.1. Interessant zu erwähnen ist das bereits 2012 11.2 Millionen
\$ von Sponsoren zur Verfügung gestellt wurden.

Vorteile - Schnell \& einfach zu lernen / entwickeln - Gute
Dokumentation - Bietet viel ``out of the box'' - Keine callback hell

Nachteile - frühes Entwicklungsstadium - Automatisiertes Testen wird
nicht unterstützt

Zukunftsaussichten

Es soll nicht nur MongoDB unterstützt werden, sondern noch viele andere
Datenbanken. Unter anderem auch SQL-Datenbanken.

Wird von manchen als möglicher Nachfolger für MEAN.io angesehen.

\subsubsection{Ausblick (Marinus)}\label{ausblick-marinus}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Angular Support bei neuer Sprache fuer v1?
\item
  Angular 2 nicht mit 1 kompatibel
\item
  Typescript als Hoffnungsausblick durch besseren Compiler,
  Typsicherheit, Klassen und definierte Standards z.B. fuer Promises und
  require
\end{itemize}

\subsection{Fazit (Marinus)}\label{fazit-marinus}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  MEAN eher nein, Teile davon schon
\item
  PostgreSQL besser als MongoDB? (2-4mal schneller?)
\item
  Konservative Entscheidung oft besser
\item
  AngularJS einfacher Einstieg, aber Support und Plugin Probleme, bei
  erfahrenen Nutzern ist Backbone/Vanilla.js vielleicht geeigneter
\item
  Angular und MongoDB(?) skalieren nicht sonderlich gut
\item
  Die Meinungen über die Zukunftsfähigkeit vom MEAN Stack reichen von
  super bis ziemlich düster.
\item
  a bad standard (bzgl. javascript im browsern) is better than no
  standard
\end{itemize}

\subsection{Anhang}\label{anhang}

\subsubsection{Danksagung?}\label{danksagung}

Angabe wer welchen Teil verfasst hat

\subsubsection{Literaturverzeichnis}\label{literaturverzeichnis}

\end{document}
