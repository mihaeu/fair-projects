\chapter{Testbarkeit}\label{testbarkeit-michi}

Viele Javascript Projekte und darunter u.a. AngularJS werben damit
leicht testbar zu sein \cite{angular-testing}.

Um die Qualität einer Single-Page Anwendung zu sichern, ist es allerdings nötig
die Anwendung auf allen Ebenen zu testen. Das heisst es sind mindestens Tests auf 
folgenden Ebenen zu schreiben:

\begin{itemize}
\item
  Frontend Unit Tests
\item
  Server Unit Tests
\item
  Integrations/E2E (End-to-End) Tests
\end{itemize}

Wir möchten die Testbarkeit eines MEAN Stacks nicht nur mit den, in
Javascript üblichen, Praktiken vergleichen, sondern sprachübergreifende
Erwartungen an die Testbarkeit einer verteilten Anwendung stellen.

Während der Vorbereitung auf dieses Projekt fanden wir keine Quellen
oder Beispielimplementierungen, welche den gesamten Testprozess des MEAN
Stacks beschreiben. Darüber hinaus haben viele häufig verwendete
Erweiterungen keine oder nur unzureichende Testabdeckung 
(z.B. Tests nur auf einer der gennanten drei Ebenen).

\section{Frontend Unit Tests}\label{frontend-unit-tests}

AngularJS unterstützt das Testframework Jasmine\cite{jasmine}. Die meisten anderen
bekannten Javascript Testframeworks werden über 3rd-Party Erweiterungen unterstützt. Wir
haben uns auf Grund der mangelnden Unterstützung der 3rd-Party Erweiterungen, für das offiziell
unterstützte Jasmine entschieden.

In der Dokumentation von AngularJS befindet sich je ein Kapitel zu Unit und
E2E Testing. Die Dokumentation erklärt auch wie Controller, Services usw.
zu testen sind, aber liefert dies nicht mit Angular. Vermutlich auf Grund der Unterstützung vieler verschiedener Testframeworks muss man für das Testen der verschiedenen Komponenten
(Controller, Services usw.) also immer den Bootstrap Code von Hand schreiben.
Dies ist allerdings nicht nur aufwändig, sondern auch fehlerträchtiger, als wenn
AngularJS nur ein Testframework unterstützen würde und die
Funktionalität für das Testen ihrer Komponenten vorgeben.

Da die Tests abhängig von der jeweiligen Browserumgebung sind, müssen
die Tests in verschiedenen Browsern ausgeführt werden (das Kapitel
\ref{testautomatisierung} beschriebt Alternativen). Fair Projects
verwendet Karma\cite{karma} um
die Tests automatisiert auf verschiedenen Browsern auszuführen.

\section{Backend Unit Tests}\label{backend-unit-tests}

In der Dokumentation von Express wird der Testvorgang oder generell
Testbarkeit nicht behandelt\cite{express-no-tests}. Wie bereits im Kapitel zu Express genannt,
ist es mit der eigentlichen Architektur von Express auch nur schwer
möglich Unit Tests zu schreiben, da Callbacks verwendet werden und keine
Dependency Injection mitgeliefert wird.

Durch die bereits beschriebenen Änderungen konnten wir zum einen unsere
Datenbankschicht (Repositories) mit Mockobjekten austauschen und durch
die Extraktion der Callbacks in eigene Funktionen war es möglich
Controller zu testen.

Auf der Suche nach empfohlenen Praktiken hat sich herausgestellt, dass
im Backend selten ausreichend getestet wird. Die vermeintlich schnelle
Entwicklung mit Javascript führt damit zu ungetestem Code, welcher
wiederum zu Wartungsproblemen führt und damit die Gesamtzeit für die Entwicklung erhöht.

Wie auch bereits für die Frontend Unit Tests, benutzten wir Jasmine als
Testframework. Es gibt andere bekannte Testframeworks wie z.B.
mocha\cite{mocha}, aber da Jasmine der Standard für
AngularJS ist, macht es Sinn dieses auch für das Backend zu verwenden um
keine weitere unnötige Abhängigkeit in das Projekt einzuführen.

Im Vergleich zu den Frontend Tests ist es leichter die Tests zu
automatisieren, da sie wie von anderen Sprachen gewohnt auf der Console
(jasmine-node\cite{jasmine-node}) oder in
der Entwicklungsumgebung ausgeführt werden können.

In Node werden sämtliche externe Aufrufe asynchron ausgeführt. Dies
führt dazu, dass das schreiben von Tests im Vergleich zu z.B. Java
relativ aufwändig ist, da die Tests trotz Mocking der externen Quellen
(in unserem Fall z.B. das \texttt{SubjectRepository}) mit Asynchronität
arbeiten müssen.

Für Fair Projects benutzen wir das Promise Framework
bluebird\cite{bluebird}. Promises lösen das Problem
der verschachtelten Callbacks (die sog. Callback Hell) und sind zudem
testbar, da man ein Promise erstellen kann, das bereits erfüllt wurde (siehe \ref{callback}).

Trotzdem ist es notwendig ein Promise Objekt für das Mockobjekt zu
erstellen. Die Tests werden dann so geschrieben, dass die Testbedingung
(assert) erst geprüft wird, wenn das Promise aus dem Mockobjekt erfüllt
ist.

\section{E2E Tests}\label{e2e-tests}

Bei End-to-End (oder auch: Systemtests) wird das gesamte System mit
allen Abhängigkeiten getestet. In anderen Sprachen wird dabei z.B. die
Bedienung der Benutzeroberfläche via
Selenium\cite{selenium} automatisiert.

Für Anwendungen die AngularJS als Frontend Framework verwenden bietet
sich \cite{protractor} an. Protractor
wurde von Google entwickelt
\cite{protractor-google}
und als Open-Source Projekt frei zur Verfügung gestellt.

Tests auf der Benutzeroberfläche haben häufig das Problem, dass die
Tests sehr instabil gegenüber Veränderungen sind. Mit Protractor kann
man sich auf AngularJS spezifische Attribute beziehen, welche sich nicht
ändern, wenn die Darstellung verändert wird. Ebenso ermöglich Protractor
die inneren Zustände abzufragen (also die Models in AngularJS) und nicht
nur die grafische Darstellung des Ergebnisses (die sich vermutlich
häufiger ändert).

E2E Tests waren somit leichter zu entwickeln und stabiler gegenüber
Änderungen, als E2E Tests wie man sie aus anderen Frameworks oder
Sprachen kennt. Dies ist jedoch kein Argument für den MEAN Stack im
gesamten, sondern jediglich für AngularJS als Frontend Framework.

Für Fair Projects haben wir die API nicht explizit getestet, da dies
auch über die E2E Tests abgedeckt wird. Manche Anwendungen verzichten
auf Unit Tests (vermutlich auf Grund der im vorigen Kapitel
beschriebenen Problematik) und testen lediglich die Endpunkte der Express API.
SuperTest\cite{supertest} ist eine
Erweiterung für Jasmine und erlaubt es für REST Anfragen die Antworten
zu testen (z.B. hinsichtlich Status Code oder Body).

\section{Testabdeckung}\label{testabdeckung}

Testabdeckung kann für alle oben genannten Testframeworks (sogar für E2E
Tests die mit Protractor geschrieben wurden\footnote{dies ist jedoch nur bedingt
sinnvoll und kann eine Abdeckung durch Unit Tests nicht ersetzen}) via
Istanbul\cite{istanbul} erfasst werden.

Istanbul speichert die gesammelten Informationen als \texttt{.lcov}
Datei (sowie in andere Formate wie z.B. Plaintext oder HTML), welche
wiederum kombiniert werden können um eine Aussage über die Testabdeckung
von Front- und Backend treffen zu können.

Die Testabdeckung kann von allen üblichen Continuous Integration Servern
wie Jenkins oder Travis analysiert werden. Darüber hinaus gibt es
Webservices wie Code Climate\cite{codeclimate}, welche sich auf Trendanalysen 
von Testabdeckung spezialisiert haben. Diesen Service verwendet auch Fair Projects.

\section{Testautomatisierung}\label{testautomatisierung}

Da es sich bei Travis um ein Open-Source Projekt handelt verwenden wir
Travis CI als Continuous Integration Server.

Dieser führt sowohl Front- als auch Backend Unit Tests bei Aktivität im
Repository aus. Die Backend Unit Tests können dabei fehlerfrei
ausgeführt werden, aber Frontend und E2E Tests sind stark abhängig von
den unterschiedlichen Browsern.

PhantomJS\cite{phantomjs} kann verwendet werden um Tests auszuführen 
die eine Browserumgebung benötigen, ohne einen echten Browser zu starten. 
Frontend Unit Tests werden auf diese Weise
von Travis gestartet, allerdings kann dies zu verfälschten Ergebnissen
(v.a. false negatives, also fehlschlagende Tests die in echten Browsern
funktionieren) führen. PhantomJS hat es uns allerdings nicht ermöglich
unsere Protractor Tests auf dem CI Server ausführen zu lassen (in unserem
Fall kam es zu false negatives).

Es ist möglich mit xvfb\footnote{X Virtual Framebuffer zur Emulation von
Displays an Servern die kein Display haben} ein Display zu emulieren.

Auch hier würden wir einen interner CI Server mit Display und echter
Browserumgebung empfehlen um korrekte Testergebnisse zu bekommen.

\chapter{Werkzeuge}\label{werkzeuge-michi}

Die folgenden Kapitel diskutieren die verschiedenen Werkzeuge, die bei
der Entwicklung von Fair Projects verwendet wurden und Alternativen,
falls vorhanden.

\section{Dependency Management}\label{dependency-management}

In jeder Node Installation ist der bereits erwähnte Node Package Manager
npm integriert. Dieser wird zur lokalen und globalen Installtion von
Node Anwendungen und Bibliotheken verwendet.

Für Abhängigkeiten im Frontend Bereich hat sich
Bower\cite{bower} durchgesetzt.

Um die Installation zu erleichtern führt npm bei der Installation der
Abhängigkeiten anschließend \texttt{bower\ install} aus.

\section{Build Management}\label{build-management}

Build Management ist v.a. aus kompilierten Sprachen wie C oder Java
bekannt. Bekannte Vertreter hierfür sind z.B. Make, Ant, Maven oder
Gradle. Aber auch in Skriptsprachen wie Ruby (Rake), Python (PyMake),
PHP (Phing) oder Javascript ist Build Management erforderlich.

Die hier vorgestellten Werkzeuge zum Build Management sind nicht nur für
MEAN Anwendungen geeignet, sondern finden in den meisten Webanwendungen
Verwendung im Frontend Bereich.

Einfache Skripte können via npm ausgeführt werden und werden automatisch
von den meisten Continuous Integration Servern unterstützt. Travis z.B.
führt automatisch \texttt{npm\ install} und \texttt{npm\ test} aus.

Für komplexere Aufgaben ist npm nicht geeignet und i.d.R. leitet npm auf
ein spezielles Build Management Werkzeug weiter.

Fair Projects verwendet Grunt\cite{grunt}, da es hierfür die
meisten Erweiterungen gibt. Gulp\cite{gulp} ist ein
weiterer bekannter Vertreter und vertritt eher den Ansatz Code over
Configuration (Grunt benutzt im Prinzip Konfiguration im JSON Format).

Grunt automatisiert bei Fair Projects folgende Aufgaben:

\begin{itemize}
\item
  statische Analysen der Javascript Dateien
\item
  komprimieren und kombinieren der Frontend Assets
\item
  startet den Node Server
\item
  ausführen aller Tests
\item
  erneutes Laden der Anwendung im Browser
\end{itemize}

Bei Änderungen an Projektdateien werden die nötigen Aktionen automatisch
erneut ausgeführt. So führen z.B. Änderungen am Frontend dazu, dass die
Anwendung im Browser neu geladen wird und Änderungen im Backend starten
zusätzlich den Server neu.

Sehr viele der Programme v.a. bzgl. den Frontend Assets sind in
Javascript geschrieben worden. Die Grunt Erweiterungen selbst sind meist
nur Wrapper für ein Konsolenskript (z.B. grunt-uncss\cite{grunt-uncss} für
uncss\cite{uncss}). Die gleiche
Funktionalität für z.B. ein Maven Plugin zur Verfügung zu stellen wäre
wenig Aufwand und somit könnte auch ein Java Projekt mit nur einem
Werkzeug zum Build Management auskommen.

Das Build Management ist somit kein reines Argument für MEAN, da die
meisten Aufgaben die von Grunt erledigt werden das Frontend betreffen
und dies Browser-bedingt immer Javascript ist.

\section{Qualitätssicherung}\label{qualituxe4tssicherung}

Wie bereits im vorigen Kapitel erwähnt, verwendet Fair Projects
statische Analysen um den Javascript Code zu prüfen. Ein klarer Vorteil
von MEAN ist hierbei, dass die gleichen Anforderungen für das Front- und Backend
gelten.

Ein klarer Nachteil von Javascript ist es allerdings, dass es sehr wenig Werkzeuge
zur Qualitätssicherung gibt. JSCS\cite{jscs} und
JSHint\cite{jshint} prüfen den Code hinsichtlich
Formatierung und einfachen Programmier-Regeln (z.B. Vergleich mit
\texttt{===} anstatt \texttt{==} oder Anweisungen die nicht erreicht
werden können).

Werkzeuge welche Architektur, Abhängigkeiten oder ähnliches prüfen gibt
es nicht. Auch bei der Suche nach Speicherlöchern muss man auf
Werkzeugunterstützung verzichten.

Viele Firmen wie Google oder Microsoft benutzen Technologien (GWT) oder
Sprachen (Typescript, Dart) die typsicher sind oder mehr Struktur bieten
und auf Javascript kompiliert werden können (siehe Ausblick).

\section{Entwicklungsumgebung}\label{entwicklungsumgebung}

Die im vorigen Kapitel genannten Eigenschaften von Javascript führen
leider dazu, dass die Entwicklungsumgebungen für Javascript nicht die
gleiche Funktionalität wie bei anderen Sprachen bereitstellen kann.

Selbst Autovervollständigung oder Dokumentation kann häufig nicht
richtig angezeigt werden, da es in Javascript mehrere Varianten gibt
Dateien einzubinden (\texttt{require}). Bei einer Sprache wie Javascript
die selbst nur eine kleine API besitzt und viel auf den Einsatz von
Fremdbibliotheken aufbaut, erschwert dies die Entwicklung.

Werkzeuge wie Grunt, JSHint usw. werden allerdings einwandfrei
unterstützt und ermöglichen ohne den Einsatz der Konsole zu arbeiten.

\section{Debugging und Profiling}\label{debugging-und-profiling}

Sehr angenehm hingegen waren unsere Erfahrungen mit Profiling und
Debugging. Da sowohl Mozilla als auch Google viel Javascript in ihren
Anwendungen verwenden besitzen beide Browser gute Debugger. Die Debugger
implementieren die typischen von einem Debugger erwarteten Funktionen
wie Breakpoints, Watches usw.

Für Debugging im Backend gibt es die Möglichkeit dies auch über den
Browser (Node
Inspector\cite{node-inspector})durchzuführen oder aber auch über Konsole oder
Entwicklungsumgebung.

Node Inspector und die Entwicklungsumgebung Webstorm verfügen ebenso
über einen Profiler mit dem CPU und Speicherverbraucht\cite{node-memory} überwacht werden
können.

\chapter{Auslieferung (Michi)}\label{auslieferung-michi}

\section{Installation}\label{installation}

Die einzige benötigte Abhängigkeit auf einem aktuellen Linux Server sind
Node und MongoDB. Beide können in der Regel über den Paketmanager der
Linux Distribution installiert werden. Alternativ reicht es meist die
gewünschte Node Version als Binärdatei herunterzuladen.

Die Installation von Fair Projects ist damit einfach auszuführen:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{git} \NormalTok{clone https://github.com/mihaeu/fair-projects}
\KeywordTok{cd} \NormalTok{fair-projects}

\CommentTok{# lädt Front- und Backend Abhängigkeiten}
\KeywordTok{npm} \NormalTok{install}

\CommentTok{# Produktion: startet den Server}
\KeywordTok{node} \NormalTok{server.js}

\CommentTok{# Entwicklung: startet Tests etc.}
\KeywordTok{npm} \NormalTok{install --global grunt-cli}
\KeywordTok{grunt}
\end{Highlighting}
\end{Shaded}

Im Vergleich zu anderen Sprachen wie Python oder PHP ist die
Auslieferung einer MEAN Anwendung schwerer, aber vom Aufwand
vergleichbar mit Java. Viele Webhosts unterstützen Node noch nicht, aber
da größere Anwendung ohnehin einen eigenen Server mit Administration
benötigen ist dies kein Kritikpunkt.

Beliebt für die Auslieferung sind
sog. PaaS (Plattform as a Service) Anbieter wie z.B. Heroku oder
EngineYard. Häufiges Ausliefern der Anwendung ist damit einfach, jedoch
steigen die Kosten bei hoher Last, so dass sich eigene Server ab einer
bestimmten Größe lohnen.

Darüber hinaus benötigt man Monitoring um Node beim Absturz oder falls
es zu einem Memoryloch kam, automatisch neu zu starten.

\section{Docker}\label{docker}

Fair Projects nutzt Docker um das Setup der verschiedenen Komponenten am
Server zu automatisieren (Provisioning). Die Anwendung wird beim
Anbieter Digital Ocean auf einem einfachen Server ausgeführt. Die Anwendung
hat dabei einen Docker Container der Front- und Backend beinhaltet und einen
weiteren Container\footnote{da es sich hierbei um den offiziellen Mongo Container
handelt befindet sich dieser nicht im Repository} für MongoDB.

Der Vorteil an diesem Ansatz ist zum einen, dass die Konfiguration der
Software kompatibel zur Version der Software ist, da beides versioniert
wird. Außerdem ist es sehr einfach die Anwendung horizontal (und
theoretisch auch) vertikal zu skalieren.

Die Kombination aus MongoDB und Node lässt sich somit leicht skalieren
(falls Sessions in der Datenbank gespeichert werden) und bei steigender
Last können auf Mausklick neue Instanzen gestartet werden.
